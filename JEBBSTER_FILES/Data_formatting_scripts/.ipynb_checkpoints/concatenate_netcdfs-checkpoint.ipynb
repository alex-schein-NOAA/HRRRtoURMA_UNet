{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b26d060b-c391-49ee-b2ea-21b99738a608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "from datetime import date, timedelta\n",
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import glob\n",
    "import dask\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d09a7e38-61dd-4e36-82b7-80e39c6a8f67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_files_for_problems(input_files):\n",
    "    #Checks if the coords from the first dataset (asssumed to be good) are in all files\n",
    "    #Far from comprehensive but usually catches if a regridded file failed for whatever reason\n",
    "    flag = 0\n",
    "    ds0 = xr.open_dataset(input_files[0], decode_timedelta=True)\n",
    "    for i, filepath in enumerate(input_files):\n",
    "        ds1 = xr.open_dataset(filepath, decode_timedelta=True)\n",
    "        if i % (int(len(input_files)/50))==0:\n",
    "            print(f\"{(i/len(input_files))*100:.0f}% of files checked\")\n",
    "        if list(ds0.coords) != list(ds1.coords):\n",
    "            print(f\"Failure in {filepath}\")\n",
    "            flag = 1\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "079b7a5f-65f8-43c7-8f58-505f1e7e7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAR_LIST = [\"u10m\", \"v10m\"]#, \"d2m\", \"pressurf\"] #t2m already checked, spfh2m not regridded yet (7/29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72ef2b98-7522-47cc-a86e-c0b77fa683e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking d2m test files\n",
      "0% of files checked\n",
      "2% of files checked\n",
      "4% of files checked\n",
      "6% of files checked\n",
      "8% of files checked\n",
      "10% of files checked\n",
      "12% of files checked\n",
      "14% of files checked\n",
      "16% of files checked\n",
      "18% of files checked\n",
      "20% of files checked\n",
      "22% of files checked\n",
      "24% of files checked\n",
      "26% of files checked\n",
      "28% of files checked\n",
      "30% of files checked\n",
      "32% of files checked\n",
      "34% of files checked\n",
      "36% of files checked\n",
      "38% of files checked\n",
      "40% of files checked\n",
      "42% of files checked\n",
      "44% of files checked\n",
      "46% of files checked\n",
      "48% of files checked\n",
      "50% of files checked\n",
      "52% of files checked\n",
      "54% of files checked\n",
      "56% of files checked\n",
      "58% of files checked\n",
      "60% of files checked\n",
      "62% of files checked\n",
      "64% of files checked\n",
      "66% of files checked\n",
      "68% of files checked\n",
      "70% of files checked\n",
      "72% of files checked\n",
      "74% of files checked\n",
      "76% of files checked\n",
      "78% of files checked\n",
      "80% of files checked\n",
      "82% of files checked\n",
      "84% of files checked\n",
      "86% of files checked\n",
      "88% of files checked\n",
      "90% of files checked\n",
      "92% of files checked\n",
      "94% of files checked\n",
      "96% of files checked\n",
      "98% of files checked\n",
      "100% of files checked\n",
      "Checking d2m train files\n",
      "0% of files checked\n",
      "2% of files checked\n",
      "4% of files checked\n",
      "6% of files checked\n",
      "8% of files checked\n",
      "10% of files checked\n",
      "12% of files checked\n",
      "14% of files checked\n",
      "16% of files checked\n",
      "18% of files checked\n",
      "20% of files checked\n",
      "22% of files checked\n",
      "24% of files checked\n",
      "26% of files checked\n",
      "28% of files checked\n",
      "30% of files checked\n",
      "32% of files checked\n",
      "34% of files checked\n",
      "36% of files checked\n",
      "38% of files checked\n",
      "40% of files checked\n",
      "42% of files checked\n",
      "44% of files checked\n",
      "46% of files checked\n",
      "48% of files checked\n",
      "50% of files checked\n",
      "52% of files checked\n",
      "54% of files checked\n",
      "56% of files checked\n",
      "58% of files checked\n",
      "60% of files checked\n",
      "62% of files checked\n",
      "64% of files checked\n",
      "66% of files checked\n",
      "68% of files checked\n",
      "70% of files checked\n",
      "72% of files checked\n",
      "74% of files checked\n",
      "76% of files checked\n",
      "78% of files checked\n",
      "80% of files checked\n",
      "82% of files checked\n",
      "84% of files checked\n",
      "86% of files checked\n",
      "88% of files checked\n",
      "90% of files checked\n",
      "92% of files checked\n",
      "94% of files checked\n",
      "96% of files checked\n",
      "98% of files checked\n",
      "100% of files checked\n",
      "Checking pressurf test files\n",
      "0% of files checked\n",
      "2% of files checked\n",
      "4% of files checked\n",
      "6% of files checked\n",
      "8% of files checked\n",
      "10% of files checked\n",
      "12% of files checked\n",
      "14% of files checked\n",
      "16% of files checked\n",
      "18% of files checked\n",
      "20% of files checked\n",
      "22% of files checked\n",
      "24% of files checked\n",
      "26% of files checked\n",
      "28% of files checked\n",
      "30% of files checked\n",
      "32% of files checked\n",
      "34% of files checked\n",
      "36% of files checked\n",
      "38% of files checked\n",
      "40% of files checked\n",
      "42% of files checked\n",
      "44% of files checked\n",
      "46% of files checked\n",
      "48% of files checked\n",
      "50% of files checked\n",
      "52% of files checked\n",
      "54% of files checked\n",
      "56% of files checked\n",
      "58% of files checked\n",
      "60% of files checked\n",
      "62% of files checked\n",
      "64% of files checked\n",
      "66% of files checked\n",
      "68% of files checked\n",
      "70% of files checked\n",
      "72% of files checked\n",
      "74% of files checked\n",
      "76% of files checked\n",
      "78% of files checked\n",
      "80% of files checked\n",
      "82% of files checked\n",
      "84% of files checked\n",
      "86% of files checked\n",
      "88% of files checked\n",
      "90% of files checked\n",
      "92% of files checked\n",
      "94% of files checked\n",
      "96% of files checked\n",
      "98% of files checked\n",
      "100% of files checked\n",
      "Checking pressurf train files\n",
      "0% of files checked\n",
      "2% of files checked\n",
      "4% of files checked\n",
      "6% of files checked\n",
      "8% of files checked\n",
      "10% of files checked\n",
      "12% of files checked\n",
      "14% of files checked\n",
      "16% of files checked\n",
      "18% of files checked\n",
      "20% of files checked\n",
      "22% of files checked\n",
      "24% of files checked\n",
      "26% of files checked\n",
      "28% of files checked\n",
      "30% of files checked\n",
      "32% of files checked\n",
      "34% of files checked\n",
      "36% of files checked\n",
      "38% of files checked\n",
      "40% of files checked\n",
      "42% of files checked\n",
      "44% of files checked\n",
      "46% of files checked\n",
      "48% of files checked\n",
      "50% of files checked\n",
      "52% of files checked\n",
      "54% of files checked\n",
      "56% of files checked\n",
      "58% of files checked\n",
      "60% of files checked\n",
      "62% of files checked\n",
      "64% of files checked\n",
      "66% of files checked\n",
      "68% of files checked\n",
      "70% of files checked\n",
      "72% of files checked\n",
      "74% of files checked\n",
      "76% of files checked\n",
      "78% of files checked\n",
      "80% of files checked\n",
      "82% of files checked\n",
      "84% of files checked\n",
      "86% of files checked\n",
      "88% of files checked\n",
      "90% of files checked\n",
      "92% of files checked\n",
      "94% of files checked\n",
      "96% of files checked\n",
      "98% of files checked\n",
      "100% of files checked\n",
      "Checking u10m test files\n",
      "0% of files checked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for VAR in VAR_LIST:\n",
    "    PATH_HRRR_TRAIN = f\"/data1/projects/RTMA/alex.schein/Regridded_HRRR_train_test/LOOSE_FILES/train_spatiallyrestricted_f01/{VAR}\"\n",
    "    PATH_HRRR_TEST = f\"/data1/projects/RTMA/alex.schein/Regridded_HRRR_train_test/LOOSE_FILES/test_spatiallyrestricted_f01/{VAR}\"\n",
    "    \n",
    "    files_train_hrrr = sorted(glob.glob(f\"{PATH_HRRR_TRAIN}/*.nc\"))\n",
    "    files_test_hrrr = sorted(glob.glob(f\"{PATH_HRRR_TEST}/*.nc\"))\n",
    "\n",
    "    print(f\"Checking {VAR} test files\")\n",
    "    flag = check_files_for_problems(files_test_hrrr)\n",
    "\n",
    "    print(f\"Checking {VAR} train files\")\n",
    "    flag = check_files_for_problems(files_train_hrrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c7b5b5-9546-4841-b700-dbe3f45639ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c36419-5b65-4dd5-a11a-218b85133397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_URMA_TRAIN = f\"/scratch/RTMA/alex.schein/URMA_train_test/train\"\n",
    "# PATH_URMA_TEST = f\"/scratch/RTMA/alex.schein/URMA_train_test/test\"\n",
    "\n",
    "PATH_HRRR_TRAIN = f\"/data1/projects/RTMA/alex.schein/Regridded_HRRR_train_test/LOOSE_FILES/train_spatiallyrestricted_f01/{VAR}\"\n",
    "PATH_HRRR_TEST = f\"/data1/projects/RTMA/alex.schein/Regridded_HRRR_train_test/LOOSE_FILES/test_spatiallyrestricted_f01/{VAR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e7c2b1-9ca0-46a5-9101-1073b7fb962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_train_urma = sorted(glob.glob(PATH_URMA_TRAIN+\"/*.nc\"))\n",
    "# files_test_urma = sorted(glob.glob(PATH_URMA_TEST+\"/*.nc\"))\n",
    "\n",
    "files_train_hrrr = sorted(glob.glob(f\"{PATH_HRRR_TRAIN}/*.nc\"))\n",
    "files_test_hrrr = sorted(glob.glob(f\"{PATH_HRRR_TEST}/*.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632bc4e0-bf26-45b4-a564-0cd89c94db8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_netcdfs(input_files, output_filepath):\n",
    "    #input: sorted glob list of filepaths to directory of loose netcdfs\n",
    "    #input: filepath, including name and .nc extension, of output master netcdf\n",
    "\n",
    "    #Check for problems in the files before wasting time \n",
    "    flag = check_files_for_problems(input_files) #Uncomment if running this for unchecked files\n",
    "    # flag = 0 #Comment if running this for unchecked files\n",
    "\n",
    "    if flag:\n",
    "        print(f\"Problems found. Not concatenating until all problems fixed\")\n",
    "    else:\n",
    "        if not os.path.exists(output_filepath): #prevents accidental overwrites if file was already written\n",
    "            trunc_input_files = input_files[1:] #to fix indexing issues - very bad but whatever\n",
    "        \n",
    "            ds0 = xr.open_dataset(input_files[0], decode_timedelta=True)\n",
    "            for i, filename in enumerate(trunc_input_files):\n",
    "                ds1 = xr.open_dataset(trunc_input_files[i], decode_timedelta=True)\n",
    "                ds0 = xr.concat([ds0,ds1], dim=\"valid_time_dim\")\n",
    "                if i % (int(len(trunc_input_files)/50))==0:\n",
    "                    print(f\"{i}/{len(trunc_input_files)} concatenated\")\n",
    "                \n",
    "            ds_concat = ds0.assign_coords(sample_idx=(\"valid_time_dim\",[i for i in range(len(input_files))])) #uses input_files, not trunc version, as length should equal # of loose netcdf files in original directory\n",
    "            ds_concat = ds_concat.swap_dims(dims_dict={\"valid_time_dim\":\"sample_idx\"})\n",
    "        \n",
    "            ds_concat.to_netcdf(output_filepath)\n",
    "            print(f\"{output_filepath} written to disk\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe97cdd-e322-42d4-9f2f-285cb86382b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only_00z_12z_files_hrrr_train = [file for file in files_train_hrrr if \"00z\" in file or \"12z\" in file]\n",
    "# only_00z_12z_files_hrrr_test = [file for file in files_test_hrrr if \"00z\" in file or \"12z\" in file]\n",
    "\n",
    "# only_00z_12z_files_urma_train = [file for file in files_train_urma if \"00z\" in file or \"12z\" in file]\n",
    "# only_00z_12z_files_urma_test = [file for file in files_test_urma if \"00z\" in file or \"12z\" in file]\n",
    "\n",
    "# #### PRIOR TO 5/23: these filenames only refer to 00z and 12z data packed into one file\n",
    "# concat_netcdfs(only_00z_12z_files_urma_test, \"/scratch/RTMA/alex.schein/URMA_train_test/test_urma_00z_12z.nc\")\n",
    "# concat_netcdfs(only_00z_12z_files_urma_train, \"/scratch/RTMA/alex.schein/URMA_train_test/train_urma_00z_12z.nc\")\n",
    "\n",
    "# concat_netcdfs(only_00z_12z_files_hrrr_test, \"/scratch/RTMA/alex.schein/Regridded_HRRR_train_test/test_hrrr_00z_12z.nc\")\n",
    "# concat_netcdfs(only_00z_12z_files_hrrr_train, \"/scratch/RTMA/alex.schein/Regridded_HRRR_train_test/train_hrrr_00z_12z.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4ff7f3-d280-4322-9a71-a07c8b5b2acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag = check_files_for_problems(files_test_hrrr)\n",
    "# flag = check_files_for_problems(files_train_hrrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a34c8c4-9aa4-4ecf-8b74-268302d1c376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### POST 5/23: these files refer to ALL times\n",
    "# ## NOTE (5/23): NEED TO REGRID HRRR FILES! Then spatially restrict, THEN concatenate...\n",
    "\n",
    "# # path_test_urma = \"/scratch/RTMA/alex.schein/URMA_train_test/test_urma_alltimes.nc\"\n",
    "# # path_train_urma = \"/scratch/RTMA/alex.schein/URMA_train_test/train_urma_alltimes.nc\"\n",
    "\n",
    "# path_train_hrrr = \"/scratch/RTMA/alex.schein/Regridded_HRRR_train_test/train_hrrr_alltimes_f01.nc\"\n",
    "# path_test_hrrr = \"/scratch/RTMA/alex.schein/Regridded_HRRR_train_test/test_hrrr_alltimes_f01.nc\"\n",
    "\n",
    "\n",
    "# ## (6/10) Only need to make new URMA files if big changes are made (e.g. new variables, new domain). Forecast time change only --> only new HRRR files need to be made\n",
    "# # if not os.path.exists(path_train_urma):\n",
    "# #     concat_netcdfs(files_train_urma, path_train_urma)\n",
    "# # else:\n",
    "# #     print(f\"{path_train_urma} already exists\")\n",
    "\n",
    "# # if not os.path.exists(path_test_urma):\n",
    "# #     concat_netcdfs(files_test_urma, path_test_urma)\n",
    "# # else:\n",
    "# #     print(f\"{path_test_urma} already exists\")\n",
    "    \n",
    "\n",
    "# if not os.path.exists(path_train_hrrr):\n",
    "#     concat_netcdfs(files_train_hrrr, path_train_hrrr)\n",
    "# else:\n",
    "#     print(f\"{path_train_hrrr} already exists\")\n",
    "\n",
    "# if not os.path.exists(path_test_hrrr):\n",
    "#     concat_netcdfs(files_test_hrrr, path_test_hrrr)\n",
    "# else:\n",
    "#     print(f\"{path_test_hrrr} already exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd321d3-71d3-40ce-b293-211abf64035f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
