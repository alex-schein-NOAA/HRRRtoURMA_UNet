{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b26d060b-c391-49ee-b2ea-21b99738a608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "from datetime import date, timedelta\n",
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import glob\n",
    "import dask\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47c36419-5b65-4dd5-a11a-218b85133397",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_URMA_TRAIN = \"/scratch/RTMA/alex.schein/URMA_train_test/train\"\n",
    "PATH_URMA_TEST = \"/scratch/RTMA/alex.schein/URMA_train_test/test\"\n",
    "\n",
    "PATH_HRRR_TRAIN = \"/scratch/RTMA/alex.schein/Regridded_HRRR_train_test/train_spatiallyrestricted_f01\"\n",
    "PATH_HRRR_TEST = \"/scratch/RTMA/alex.schein/Regridded_HRRR_train_test/test_spatiallyrestricted_f01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1e7c2b1-9ca0-46a5-9101-1073b7fb962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_train_urma = sorted(glob.glob(PATH_URMA_TRAIN+\"/*.nc\"))\n",
    "files_test_urma = sorted(glob.glob(PATH_URMA_TEST+\"/*.nc\"))\n",
    "\n",
    "files_train_hrrr = sorted(glob.glob(PATH_HRRR_TRAIN+\"/*.nc\"))\n",
    "files_test_hrrr = sorted(glob.glob(PATH_HRRR_TEST+\"/*.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d09a7e38-61dd-4e36-82b7-80e39c6a8f67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_files_for_problems(input_files):\n",
    "    #Checks if the coords from the first dataset (asssumed to be good) are in all files\n",
    "    #Far from comprehensive but usually catches if a regridded file failed for whatever reason\n",
    "    flag = 0\n",
    "    ds0 = xr.open_dataset(input_files[0], decode_timedelta=True)\n",
    "    for i, filepath in enumerate(input_files):\n",
    "        ds1 = xr.open_dataset(filepath, decode_timedelta=True)\n",
    "        if i % (int(len(input_files)/50))==0:\n",
    "            print(f\"{i}/{len(input_files)} files checked\")\n",
    "        if list(ds0.coords) != list(ds1.coords):\n",
    "            print(f\"Failure in {filepath}\")\n",
    "            flag = 1\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "632bc4e0-bf26-45b4-a564-0cd89c94db8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_netcdfs(input_files, output_filepath):\n",
    "    #input: sorted glob list of filepaths to directory of loose netcdfs\n",
    "    #input: filepath, including name and .nc extension, of output master netcdf\n",
    "\n",
    "    #Check for problems in the files before wasting time \n",
    "    flag = check_files_for_problems(input_files) #Uncomment if running this for unchecked files\n",
    "    # flag = 0 #Comment if running this for unchecked files\n",
    "\n",
    "    if flag:\n",
    "        print(f\"Problems found. Not concatenating until all problems fixed\")\n",
    "    else:\n",
    "        if not os.path.exists(output_filepath): #prevents accidental overwrites if file was already written\n",
    "            trunc_input_files = input_files[1:] #to fix indexing issues - very bad but whatever\n",
    "        \n",
    "            ds0 = xr.open_dataset(input_files[0], decode_timedelta=True)\n",
    "            for i, filename in enumerate(trunc_input_files):\n",
    "                ds1 = xr.open_dataset(trunc_input_files[i], decode_timedelta=True)\n",
    "                ds0 = xr.concat([ds0,ds1], dim=\"valid_time_dim\")\n",
    "                if i % (int(len(trunc_input_files)/50))==0:\n",
    "                    print(f\"{i}/{len(trunc_input_files)} concatenated\")\n",
    "                \n",
    "            ds_concat = ds0.assign_coords(sample_idx=(\"valid_time_dim\",[i for i in range(len(input_files))])) #uses input_files, not trunc version, as length should equal # of loose netcdf files in original directory\n",
    "            ds_concat = ds_concat.swap_dims(dims_dict={\"valid_time_dim\":\"sample_idx\"})\n",
    "        \n",
    "            ds_concat.to_netcdf(output_filepath)\n",
    "            print(f\"{output_filepath} written to disk\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fe97cdd-e322-42d4-9f2f-285cb86382b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only_00z_12z_files_hrrr_train = [file for file in files_train_hrrr if \"00z\" in file or \"12z\" in file]\n",
    "# only_00z_12z_files_hrrr_test = [file for file in files_test_hrrr if \"00z\" in file or \"12z\" in file]\n",
    "\n",
    "# only_00z_12z_files_urma_train = [file for file in files_train_urma if \"00z\" in file or \"12z\" in file]\n",
    "# only_00z_12z_files_urma_test = [file for file in files_test_urma if \"00z\" in file or \"12z\" in file]\n",
    "\n",
    "# #### PRIOR TO 5/23: these filenames only refer to 00z and 12z data packed into one file\n",
    "# concat_netcdfs(only_00z_12z_files_urma_test, \"/scratch/RTMA/alex.schein/URMA_train_test/test_urma_00z_12z.nc\")\n",
    "# concat_netcdfs(only_00z_12z_files_urma_train, \"/scratch/RTMA/alex.schein/URMA_train_test/train_urma_00z_12z.nc\")\n",
    "\n",
    "# concat_netcdfs(only_00z_12z_files_hrrr_test, \"/scratch/RTMA/alex.schein/Regridded_HRRR_train_test/test_hrrr_00z_12z.nc\")\n",
    "# concat_netcdfs(only_00z_12z_files_hrrr_train, \"/scratch/RTMA/alex.schein/Regridded_HRRR_train_test/train_hrrr_00z_12z.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a34c8c4-9aa4-4ecf-8b74-268302d1c376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/26280 files checked\n",
      "525/26280 files checked\n",
      "1050/26280 files checked\n",
      "1575/26280 files checked\n",
      "2100/26280 files checked\n",
      "2625/26280 files checked\n",
      "3150/26280 files checked\n",
      "3675/26280 files checked\n",
      "4200/26280 files checked\n",
      "4725/26280 files checked\n",
      "5250/26280 files checked\n",
      "5775/26280 files checked\n",
      "6300/26280 files checked\n",
      "6825/26280 files checked\n",
      "7350/26280 files checked\n",
      "7875/26280 files checked\n",
      "8400/26280 files checked\n",
      "8925/26280 files checked\n",
      "9450/26280 files checked\n",
      "9975/26280 files checked\n",
      "10500/26280 files checked\n",
      "11025/26280 files checked\n",
      "11550/26280 files checked\n",
      "12075/26280 files checked\n",
      "12600/26280 files checked\n",
      "13125/26280 files checked\n",
      "13650/26280 files checked\n",
      "14175/26280 files checked\n",
      "14700/26280 files checked\n",
      "15225/26280 files checked\n",
      "15750/26280 files checked\n",
      "16275/26280 files checked\n",
      "16800/26280 files checked\n",
      "17325/26280 files checked\n",
      "17850/26280 files checked\n",
      "18375/26280 files checked\n",
      "18900/26280 files checked\n",
      "19425/26280 files checked\n",
      "19950/26280 files checked\n",
      "20475/26280 files checked\n",
      "21000/26280 files checked\n",
      "21525/26280 files checked\n",
      "22050/26280 files checked\n",
      "22575/26280 files checked\n",
      "23100/26280 files checked\n",
      "23625/26280 files checked\n",
      "24150/26280 files checked\n",
      "24675/26280 files checked\n",
      "25200/26280 files checked\n",
      "25725/26280 files checked\n",
      "26250/26280 files checked\n",
      "0/26279 concatenated\n",
      "525/26279 concatenated\n",
      "1050/26279 concatenated\n",
      "1575/26279 concatenated\n",
      "2100/26279 concatenated\n",
      "2625/26279 concatenated\n",
      "3150/26279 concatenated\n",
      "3675/26279 concatenated\n",
      "4200/26279 concatenated\n",
      "4725/26279 concatenated\n",
      "5250/26279 concatenated\n",
      "5775/26279 concatenated\n",
      "6300/26279 concatenated\n",
      "6825/26279 concatenated\n",
      "7350/26279 concatenated\n",
      "7875/26279 concatenated\n",
      "8400/26279 concatenated\n",
      "8925/26279 concatenated\n",
      "9450/26279 concatenated\n",
      "9975/26279 concatenated\n",
      "10500/26279 concatenated\n",
      "11025/26279 concatenated\n",
      "11550/26279 concatenated\n",
      "12075/26279 concatenated\n",
      "12600/26279 concatenated\n",
      "13125/26279 concatenated\n",
      "13650/26279 concatenated\n",
      "14175/26279 concatenated\n",
      "14700/26279 concatenated\n",
      "15225/26279 concatenated\n",
      "15750/26279 concatenated\n",
      "16275/26279 concatenated\n",
      "16800/26279 concatenated\n",
      "17325/26279 concatenated\n",
      "17850/26279 concatenated\n",
      "18375/26279 concatenated\n",
      "18900/26279 concatenated\n",
      "19425/26279 concatenated\n",
      "19950/26279 concatenated\n",
      "20475/26279 concatenated\n",
      "21000/26279 concatenated\n",
      "21525/26279 concatenated\n",
      "22050/26279 concatenated\n",
      "22575/26279 concatenated\n",
      "23100/26279 concatenated\n",
      "23625/26279 concatenated\n",
      "24150/26279 concatenated\n",
      "24675/26279 concatenated\n",
      "25200/26279 concatenated\n",
      "25725/26279 concatenated\n",
      "26250/26279 concatenated\n",
      "/scratch/RTMA/alex.schein/Regridded_HRRR_train_test/train_hrrr_alltimes_f01.nc written to disk\n",
      "0/8783 files checked\n",
      "175/8783 files checked\n",
      "350/8783 files checked\n",
      "525/8783 files checked\n",
      "700/8783 files checked\n",
      "875/8783 files checked\n",
      "1050/8783 files checked\n",
      "1225/8783 files checked\n",
      "1400/8783 files checked\n",
      "1575/8783 files checked\n",
      "1750/8783 files checked\n",
      "1925/8783 files checked\n",
      "2100/8783 files checked\n",
      "2275/8783 files checked\n",
      "2450/8783 files checked\n",
      "2625/8783 files checked\n",
      "2800/8783 files checked\n",
      "2975/8783 files checked\n",
      "3150/8783 files checked\n",
      "3325/8783 files checked\n",
      "3500/8783 files checked\n",
      "3675/8783 files checked\n",
      "3850/8783 files checked\n",
      "4025/8783 files checked\n",
      "4200/8783 files checked\n",
      "4375/8783 files checked\n",
      "4550/8783 files checked\n",
      "4725/8783 files checked\n",
      "4900/8783 files checked\n",
      "5075/8783 files checked\n",
      "5250/8783 files checked\n",
      "5425/8783 files checked\n",
      "5600/8783 files checked\n",
      "5775/8783 files checked\n",
      "5950/8783 files checked\n",
      "6125/8783 files checked\n",
      "6300/8783 files checked\n",
      "6475/8783 files checked\n",
      "6650/8783 files checked\n",
      "6825/8783 files checked\n",
      "7000/8783 files checked\n",
      "7175/8783 files checked\n",
      "7350/8783 files checked\n",
      "7525/8783 files checked\n",
      "7700/8783 files checked\n",
      "7875/8783 files checked\n",
      "8050/8783 files checked\n",
      "8225/8783 files checked\n",
      "8400/8783 files checked\n",
      "8575/8783 files checked\n",
      "8750/8783 files checked\n",
      "0/8782 concatenated\n",
      "175/8782 concatenated\n",
      "350/8782 concatenated\n",
      "525/8782 concatenated\n",
      "700/8782 concatenated\n",
      "875/8782 concatenated\n",
      "1050/8782 concatenated\n",
      "1225/8782 concatenated\n",
      "1400/8782 concatenated\n",
      "1575/8782 concatenated\n",
      "1750/8782 concatenated\n",
      "1925/8782 concatenated\n",
      "2100/8782 concatenated\n",
      "2275/8782 concatenated\n",
      "2450/8782 concatenated\n",
      "2625/8782 concatenated\n",
      "2800/8782 concatenated\n",
      "2975/8782 concatenated\n",
      "3150/8782 concatenated\n",
      "3325/8782 concatenated\n",
      "3500/8782 concatenated\n",
      "3675/8782 concatenated\n",
      "3850/8782 concatenated\n",
      "4025/8782 concatenated\n",
      "4200/8782 concatenated\n",
      "4375/8782 concatenated\n",
      "4550/8782 concatenated\n",
      "4725/8782 concatenated\n",
      "4900/8782 concatenated\n",
      "5075/8782 concatenated\n",
      "5250/8782 concatenated\n",
      "5425/8782 concatenated\n",
      "5600/8782 concatenated\n",
      "5775/8782 concatenated\n",
      "5950/8782 concatenated\n",
      "6125/8782 concatenated\n",
      "6300/8782 concatenated\n",
      "6475/8782 concatenated\n",
      "6650/8782 concatenated\n",
      "6825/8782 concatenated\n",
      "7000/8782 concatenated\n",
      "7175/8782 concatenated\n",
      "7350/8782 concatenated\n",
      "7525/8782 concatenated\n",
      "7700/8782 concatenated\n",
      "7875/8782 concatenated\n",
      "8050/8782 concatenated\n",
      "8225/8782 concatenated\n",
      "8400/8782 concatenated\n",
      "8575/8782 concatenated\n",
      "8750/8782 concatenated\n",
      "/scratch/RTMA/alex.schein/Regridded_HRRR_train_test/test_hrrr_alltimes_f01.nc written to disk\n"
     ]
    }
   ],
   "source": [
    "#### POST 5/23: these files refer to ALL times\n",
    "## NOTE (5/23): NEED TO REGRID HRRR FILES! Then spatially restrict, THEN concatenate...\n",
    "\n",
    "# path_test_urma = \"/scratch/RTMA/alex.schein/URMA_train_test/test_urma_alltimes.nc\"\n",
    "# path_train_urma = \"/scratch/RTMA/alex.schein/URMA_train_test/train_urma_alltimes.nc\"\n",
    "\n",
    "path_train_hrrr = \"/scratch/RTMA/alex.schein/Regridded_HRRR_train_test/train_hrrr_alltimes_f01.nc\"\n",
    "path_test_hrrr = \"/scratch/RTMA/alex.schein/Regridded_HRRR_train_test/test_hrrr_alltimes_f01.nc\"\n",
    "\n",
    "\n",
    "## (6/10) Only need to make new URMA files if big changes are made (e.g. new variables, new domain). Forecast time change only --> only new HRRR files need to be made\n",
    "# if not os.path.exists(path_train_urma):\n",
    "#     concat_netcdfs(files_train_urma, path_train_urma)\n",
    "# else:\n",
    "#     print(f\"{path_train_urma} already exists\")\n",
    "\n",
    "# if not os.path.exists(path_test_urma):\n",
    "#     concat_netcdfs(files_test_urma, path_test_urma)\n",
    "# else:\n",
    "#     print(f\"{path_test_urma} already exists\")\n",
    "    \n",
    "\n",
    "if not os.path.exists(path_train_hrrr):\n",
    "    concat_netcdfs(files_train_hrrr, path_train_hrrr)\n",
    "else:\n",
    "    print(f\"{path_train_hrrr} already exists\")\n",
    "\n",
    "if not os.path.exists(path_test_hrrr):\n",
    "    concat_netcdfs(files_test_hrrr, path_test_hrrr)\n",
    "else:\n",
    "    print(f\"{path_test_hrrr} already exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd321d3-71d3-40ce-b293-211abf64035f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
