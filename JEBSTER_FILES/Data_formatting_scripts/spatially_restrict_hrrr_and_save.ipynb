{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b58a7a3f-8ab5-4a05-b08f-fd5b0ea83c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "from datetime import date, timedelta\n",
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53be031d-55af-4a2e-b9d0-6f0740156ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX_MIN_LON = 595+1 #NOTE: different from URMA grid! \n",
    "IDX_MIN_LAT = 645\n",
    "\n",
    "IMG_SIZE_LON = 180\n",
    "IMG_SIZE_LAT = 180\n",
    "\n",
    "TIME_LIST = [str(i).zfill(2) for i in range(24)] #[\"00\", \"12\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ac3fb7e-267f-45a8-9a6a-29b62f3ae216",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAR_OF_INTEREST = \"pressurf\"\n",
    "\n",
    "PATH_HRRR_ORIGINAL = f\"/data1/projects/RTMA/alex.schein/Regridded_HRRR/{VAR_OF_INTEREST}\"\n",
    "PATH_TRAIN = f\"/data1/projects/RTMA/alex.schein/Regridded_HRRR_train_test/LOOSE_FILES/train_spatiallyrestricted_f01/{VAR_OF_INTEREST}\"\n",
    "PATH_TEST = f\"/data1/projects/RTMA/alex.schein/Regridded_HRRR_train_test/LOOSE_FILES/test_spatiallyrestricted_f01/{VAR_OF_INTEREST}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f735f06d-346c-415e-8e63-96120ac75054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START_DATE_TRAIN = date(2021,1,1) #should be jan 1, 2021\n",
    "# END_DATE_TRAIN = date(2023,12,31) #should be dec 31, 2023\n",
    "# NUM_DAYS_TRAIN = END_DATE_TRAIN-START_DATE_TRAIN\n",
    "\n",
    "# START_DATE_TEST = date(2024,1,1) #should be jan 1, 2024\n",
    "# END_DATE_TEST = date(2024,12,31) #should be dec 31, 2024\n",
    "# NUM_DAYS_TEST = END_DATE_TEST-START_DATE_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dfea967-52a5-427d-9ddf-c72f28cd263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_files(START_DATE, END_DATE, TIME_LIST, PATH_ORIGINAL, PATH_NEW, IDX_MIN_LON=596, IDX_MIN_LAT=645, IMG_SIZE_LON=180, IMG_SIZE_LAT=180):\n",
    "    # NOTE: default idx mins are for HRRR - need to change if using this for URMA!\n",
    "    NUM_DAYS = END_DATE-START_DATE\n",
    "    for i in range(NUM_DAYS.days+1):\n",
    "        DATE_STR = date.strftime(START_DATE + timedelta(days=i), \"%Y%m%d\")\n",
    "        filenames = os.listdir(f\"{PATH_ORIGINAL}/{DATE_STR}\")\n",
    "        for time in TIME_LIST:\n",
    "            # if len(filenames)<len(TIME_LIST): #this is for degenerate cases like f01 on 2020/12/31 23z\n",
    "                \n",
    "            # else:\n",
    "            filename = [x for x in filenames if f\"t{time}z\" in x and \".idx\" not in x][0]\n",
    "            new_filename = f\"hrrr_regridded_spatiallyrestricted_{DATE_STR}_t{time}z.nc\"\n",
    "            if not os.path.exists(f\"{PATH_NEW}/{new_filename}\"):\n",
    "                var = xr.open_dataset(f\"{PATH_ORIGINAL}/{DATE_STR}/{filename}\", engine=\"cfgrib\", decode_timedelta=True)\n",
    "                var_subset = var.isel(y=slice(IDX_MIN_LAT, IDX_MIN_LAT+IMG_SIZE_LAT),\n",
    "                                      x=slice(IDX_MIN_LON, IDX_MIN_LON+IMG_SIZE_LON))\n",
    "                var_subset.to_netcdf(f\"{PATH_NEW}/{new_filename}\")\n",
    "                print(f\"{new_filename} written to {PATH_NEW}\")\n",
    "            else:\n",
    "                print(f\"{new_filename} already exists in {PATH_NEW}. No action taken\")\n",
    "                \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f9710ae-ff95-41fc-8f6a-2ce2de10b6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrrr_regridded_spatiallyrestricted_20201231_t23z.nc written to /data1/projects/RTMA/alex.schein/Regridded_HRRR_train_test/LOOSE_FILES/train_spatiallyrestricted_f01/d2m\n"
     ]
    }
   ],
   "source": [
    "restrict_files(START_DATE=date(2020,12,31),\n",
    "               END_DATE=date(2020,12,31), \n",
    "               TIME_LIST=[\"23\"],\n",
    "               PATH_ORIGINAL=PATH_HRRR_ORIGINAL,\n",
    "               PATH_NEW=PATH_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab143dc5-f212-4ed7-b7c0-c0b35247e107",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# restrict_files(START_DATE=date(2021,1,1),\n",
    "#                END_DATE=date(2023,12,31), \n",
    "#                TIME_LIST=TIME_LIST,\n",
    "#                PATH_ORIGINAL=PATH_HRRR_ORIGINAL,\n",
    "#                PATH_NEW=PATH_TRAIN)\n",
    "\n",
    "# restrict_files(START_DATE=date(2024,1,1),\n",
    "#                END_DATE=date(2024,12,31), \n",
    "#                TIME_LIST=TIME_LIST,\n",
    "#                PATH_ORIGINAL=PATH_HRRR_ORIGINAL,\n",
    "#                PATH_NEW=PATH_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd6b3b1-8502-421e-9d44-7f54e9604138",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # All 2021-2023 files to PATH_TRAIN directory\n",
    "# for i in range(NUM_DAYS_TRAIN.days + 1):\n",
    "#     DATE_STR_TRAIN = date.strftime(START_DATE_TRAIN + timedelta(days=i), \"%Y%m%d\")\n",
    "#     filenames = os.listdir(PATH_HRRR_ORIGINAL+\"/\"+DATE_STR_TRAIN)\n",
    "#     for time in TIME_LIST:\n",
    "#         filename = [x for x in filenames if f\"t{time}z\" in x and \".idx\" not in x][0] #unlike URMA, these have forecast times in the filenames, so can mess up if just using digits\n",
    "#         new_filename = f\"hrrr_regridded_spatiallyrestricted_{DATE_STR_TRAIN}_t{time}z.nc\"\n",
    "#         if not os.path.exists(PATH_TRAIN+f\"/{new_filename}\"): #skip files that already exist in destination folder\n",
    "#             t2m = xr.open_dataset(PATH_HRRR_ORIGINAL+\"/\"+DATE_STR_TRAIN+\"/\"+filename, engine='cfgrib', decode_timedelta=True)\n",
    "#             t2m_subset = t2m.isel(y=slice(IDX_MIN_LAT, IDX_MIN_LAT+IMG_SIZE_LAT),\n",
    "#                                   x=slice(IDX_MIN_LON, IDX_MIN_LON+IMG_SIZE_LON))\n",
    "#             t2m_subset.to_netcdf(PATH_TRAIN+\"/\"+new_filename)#, encoding={\"t2m\":{\"zlib\":True, \"complevel\":9}}) #(6/16) DON'T USE ENCODING - though it saves space, it automatically enables chunking which is SUPER slow!\n",
    "#             print(f\"{new_filename} written to {PATH_TRAIN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172847b7-2bd9-4b8d-ae61-965124ed09a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # # All 2024 files to PATH_TEST directory\n",
    "# for i in range(NUM_DAYS_TEST.days + 1):\n",
    "#     DATE_STR_TEST = date.strftime(START_DATE_TEST + timedelta(days=i), \"%Y%m%d\")\n",
    "#     filenames = os.listdir(PATH_HRRR_ORIGINAL+\"/\"+DATE_STR_TEST)\n",
    "#     for time in TIME_LIST:\n",
    "#         filename = [x for x in filenames if f\"t{time}z\" in x and \".idx\" not in x][0] #unlike URMA, these have forecast times in the filenames, so can mess up if just using digits\n",
    "#         new_filename = f\"hrrr_regridded_spatiallyrestricted_{DATE_STR_TEST}_t{time}z.nc\"\n",
    "#         if not os.path.exists(PATH_TEST+f\"/{new_filename}\"): #skip files that already exist in destination folder\n",
    "#             t2m = xr.open_dataset(PATH_HRRR_ORIGINAL+\"/\"+DATE_STR_TEST+\"/\"+filename, engine='cfgrib', decode_timedelta=True)\n",
    "#             t2m_subset = t2m.isel(y=slice(IDX_MIN_LAT, IDX_MIN_LAT+IMG_SIZE_LAT),\n",
    "#                                   x=slice(IDX_MIN_LON, IDX_MIN_LON+IMG_SIZE_LON))\n",
    "#             t2m_subset.to_netcdf(PATH_TEST+\"/\"+new_filename)#, encoding={\"t2m\":{\"zlib\":True, \"complevel\":9}})\n",
    "#             print(f\"{new_filename} written to {PATH_TEST}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19809aea-6e94-4e1e-ac5e-46516b4eeeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do the 2020/12/31 23z file on its own here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516d58ef-b1b9-4c67-9d87-849d34c8032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t2m = xr.open_dataset(PATH_HRRR_ORIGINAL+\"/\"+\"20201231/hrrr_regridded_20201231_t23z_f01.grib2\", engine='cfgrib', decode_timedelta=True)\n",
    "# t2m_subset = t2m.isel(y=slice(IDX_MIN_LAT, IDX_MIN_LAT+IMG_SIZE_LAT),\n",
    "#                       x=slice(IDX_MIN_LON, IDX_MIN_LON+IMG_SIZE_LON))\n",
    "# t2m_subset.to_netcdf(PATH_TRAIN+\"/\"+\"hrrr_regridded_spatiallyrestricted_20201231_t23z.nc\")#, encoding={\"t2m\":{\"zlib\":True, \"complevel\":9}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e5ce65-53b2-41c2-8fee-6b2d001e7189",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lat/lon index testing\n",
    "# t2m = xr.open_dataset(\"/scratch/RTMA/alex.schein/test_hrrr_newgrid.grib2\", engine='cfgrib', decode_timedelta=True)\n",
    "# t2m_subset = t2m.isel(y=slice(IDX_MIN_LAT, IDX_MIN_LAT+IMG_SIZE_LAT),\n",
    "#                       x=slice(IDX_MIN_LON, IDX_MIN_LON+IMG_SIZE_LON))\n",
    "# t2m_subset.to_netcdf(\"/scratch/RTMA/alex.schein/test_hrrr_newgrid_regridded.grib2\", encoding={\"t2m\":{\"zlib\":True, \"complevel\":9}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
